# Import necessary libraries
import tensorflow as tf
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt

# 1️⃣ Load the MNIST dataset (handwritten digits)
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

# Normalize pixel values from [0,255] to [0,1]
x_train = x_train / 255.0
x_test = x_test / 255.0

# 2️⃣ Build the Feedforward Neural Network (MLP)
model = models.Sequential([
    layers.Flatten(input_shape=(28, 28)),  # Convert 28x28 image → 784 vector
    layers.Dense(256, activation='relu'),   # Hidden layer 1
    layers.Dense(128, activation='relu'),   # Hidden layer 2
    layers.Dense(10, activation='softmax')  # Output layer (10 classes)
])

# 3️⃣ Compile the model
model.compile(
    optimizer='adam',                      # Optimizer
    loss='sparse_categorical_crossentropy', # Loss function for integer labels
    metrics=['accuracy']                    # Metric to monitor
)

# 4️⃣ Train the model
history = model.fit(
    x_train, y_train,
    epochs=5,               # Train for 5 epochs
    batch_size=64,          # Use 64 images per training step
    validation_data=(x_test, y_test)  # Check performance on test data each epoch
)

# 5️⃣ Evaluate on test data
test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)
print(f"\n✅ Test Accuracy: {test_accuracy * 100:.2f}%")

# 6️⃣ Plot training loss and accuracy curves
plt.figure(figsize=(10,4))

# Plot loss
plt.subplot(1,2,1)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Test Loss')
plt.title('Loss Curve')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

# Plot accuracy
plt.subplot(1,2,2)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Test Accuracy')
plt.title('Accuracy Curve')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.show()

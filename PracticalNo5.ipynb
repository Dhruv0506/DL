# Import libraries
import tensorflow as tf
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt

# 1️⃣ Load and preprocess the MNIST dataset
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

# CNN expects 4D input: (samples, height, width, channels)
x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0
x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0

# 2️⃣ Data Augmentation (make training data more diverse)
datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rotation_range=10,       # rotate images by 10 degrees
    width_shift_range=0.1,   # shift left/right by 10%
    height_shift_range=0.1,  # shift up/down by 10%
    zoom_range=0.1           # random zoom
)
datagen.fit(x_train)

# 3️⃣ Build a Simple CNN model
def build_cnn():
    model = models.Sequential([
        layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),
        layers.MaxPooling2D((2,2)),
        layers.Conv2D(64, (3,3), activation='relu'),
        layers.MaxPooling2D((2,2)),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dense(10, activation='softmax')
    ])
    model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    return model

cnn_model = build_cnn()
cnn_model.summary()

# 4️⃣ Train the CNN using augmented data
history_cnn = cnn_model.fit(
    datagen.flow(x_train, y_train, batch_size=64),
    epochs=5,
    validation_data=(x_test, y_test)
)

# 5️⃣ Build and Train a Simple MLP (for comparison)
mlp_model = models.Sequential([
    layers.Flatten(input_shape=(28,28,1)),
    layers.Dense(256, activation='relu'),
    layers.Dense(128, activation='relu'),
    layers.Dense(10, activation='softmax')
])
mlp_model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
history_mlp = mlp_model.fit(
    x_train, y_train, epochs=5, batch_size=64,
    validation_data=(x_test, y_test)
)

# 6️⃣ Plot accuracy and loss curves
plt.figure(figsize=(12,5))

# Accuracy
plt.subplot(1,2,1)
plt.plot(history_mlp.history['val_accuracy'], label='MLP')
plt.plot(history_cnn.history['val_accuracy'], label='CNN')
plt.title('Validation Accuracy')
plt.xlabel('Epoch'); plt.ylabel('Accuracy')
plt.legend()

# Loss
plt.subplot(1,2,2)
plt.plot(history_mlp.history['val_loss'], label='MLP')
plt.plot(history_cnn.history['val_loss'], label='CNN')
plt.title('Validation Loss')
plt.xlabel('Epoch'); plt.ylabel('Loss')
plt.legend()

plt.show()

# 7️⃣ Evaluate both models
mlp_acc = mlp_model.evaluate(x_test, y_test, verbose=0)[1] * 100
cnn_acc = cnn_model.evaluate(x_test, y_test, verbose=0)[1] * 100

print(f"\nMLP Accuracy: {mlp_acc:.2f}%")
print(f"CNN Accuracy: {cnn_acc:.2f}%")
